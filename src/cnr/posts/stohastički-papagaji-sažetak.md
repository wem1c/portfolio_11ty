---
title: "ğŸ¦œ StohastiÄki papagaji: SaÅ¾etak (donekle)."
description: "Minimalne informacije koje biste trebali znati o problemima s velikim jeziÄnim modelima."
category: "istraÅ¾ivanja"
date: "2023-03-27"
bannerImage: "/images/posts/stochastic-parrots-a-summary.jpg"
bannerImageAlt: "image of a colorful parrot"
bannerImageAttribute: 'Photo by <a href="https://unsplash.com/@davidclode?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">David Clode</a> on <a href="https://unsplash.com/photos/G7Jd9fMuRHs?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>'
altLocaleUrl: "/en/blog/stochastic-parrots-a-summary.html"
tags: posts_cnr
---

# ğŸ¦œ StohastiÄki papagaji: SaÅ¾etak (donekle).

ProÅ¡le nedelje, naiÅ¡ao sam na [nauÄni rad](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) pod nazivom: â€œOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ğŸ¦œâ€ (Da, sa emotikonom!). MeÄ‘u Äetvoro autora bile su i bivÅ¡e voditeljice Google-ovog tima za AI etiku, Timnit Gebru i Margaret Mitchell. OtpuÅ¡tene su zbog ovog rada koji su objavile. Ako to nije dovoljan podsticaj da sami proÄitate rad, dozvolite mi da pomenem neke stvari pokrivene u istom u nadi da vas dodatno podstaknem.

## Å ta: OPJ, a ne RPJ.

Ako niÅ¡ta drugo, Å¾elim da upamtite samo ovo: **JeziÄni modeli ne razumiju jezik.**

Oni ne vrÅ¡e _Razumijevanje_ Prirodnog Jezika (krat. RPJ; en. _NLU - Natural Language Understanding_), veÄ‡ _Obradu_ Prirodnog Jezika (krat. OPJ; en. _NLP - Natural Langue Processing_).

JeziÄni modeli obraÄ‘uju ulaz koji im dajemo u odnosu na skup podataka na kojem su obuÄeni. Ovaj skup podataka je (obiÄno) samo gomila tekstova sa interneta (jedva) oÄiÅ¡Ä‡enih od nepoÅ¾eljnog sadrÅ¾aja kao Å¡to su rijeÄi koje se odnose na rasizam, seksizam, nasilje, itd. Zatim se povezuju sa razliÄitim vrijednostima koje predstavljaju informacije kao Å¡to su tema na koju se odnose ili tonalitet teksta.

Kada upitate ove modele neÅ¡to putem raznih AI rjeÅ¡enja koja ih koriste, kao Å¡to je [_ChatGPT_](https://chatgpt.com/), bazni jeziÄni model pokuÅ¡ava da poveÅ¾e ono Å¡to ste pitali sa najbliÅ¾im odgovarajuÄ‡im informacijama koje ima u svojoj bazi podataka (skupu podataka na kojem je uÄen), i zatim vam to vraÄ‡a formatirano tako da podsjeÄ‡a na ljudski govor. On zapravo ne razumije Å¡ta ste pitali niti Å¡ta je vratio - samo da su ta dva pojma blisko povezana na osnovu informacija na kojima je obuÄen.

## Kako: nasumiÄno.

ZnajuÄ‡i osnovni proces, logiÄno biste zakljuÄili da Å¡to je veÄ‡i skup podataka, to su bolji rezultati. PretpostavljajuÄ‡i da je ovo taÄno, sada razmiÅ¡ljate o tome koliko veliki skup podata moÅ¾e biti. Teoretski, sve dok to moÅ¾ete obraditi na vrijeme, veliÄina nije ograniÄena. u realnosti, ne kreirate nov skup podataka od nule piÅ¡uÄ‡i ga ruÄno. ZaÅ¡to biste? Imate postojeÄ‡i ogroman arhiv tekstova napisanih od strane ljudi, koji sadrÅ¾i svo znanje ovog sveta, na dohvat ruke - _internet_.

NajveÄ‡i jeziÄni modeli do danas, _OpenAI_-jev _GPT3_ i _Google_-ovi _GShard_ i _Switch-C_, imaju milijarde i trilione parametara, kao i skupove podataka do 745 gigabajta. 745 gigabajta slova, rijeÄi, reÄenica. Bez fotografija, video zapisa, 3D simulacija, iÄega Å¡to je znaÄajne veliÄine za moderne standarde. Ovi skupovi podataka se sastoje od pretraÅ¾enih tekstova sa _Wikipedije_, _Reddit_-a, vijesti, druÅ¡tvenih mreÅ¾a i svega ostalog Å¡to je pronaÄ‘eno u poslednjih deceniju ili dvije postojanja interneta.

I sve dok je to malo oÄiÅ¡Ä‡eno, situacija je sjajna! Ne moÅ¾e biti ikakvih problema, zar ne?

## Problemi: brojni.

PoÄnimo sa uticajem na Å¾ivotnu sredinu koji stvaranje ovakvih zvijeri ima. Procjenjuje se da obuka jednog _BERT_ baznog modela zahtijeva onoliko energije koliko i transatlantski let. I dok bi dio iskoriÅ¡tene energije mogao biti zelen (dobijen iz obnovljivih izvora ili kompenzovan ugljeniÄnim kreditima) - veÄ‡ina nije.

I to je cijena hranjena modela loÅ¡im podacima. VeÄ‡ina korisnika interneta su mlaÄ‘i ljudi iz razvijenih zemalja. VeÄ‡ina korisnika _Reddit_-a su muÅ¡karci, a samo 8-15% Wikipedijanaca su Å¾ene. PoÅ¡to se baziraju na pretraÅ¾enim podacima sa interneta, ovo znaÄi da naÅ¡i skupovi podataka uopÅ¡te nemaju raznolikost i ne ukljuÄuju veliki dio ljudske populacije. Ne samo to, veÄ‡ su djelovi interneta koji sadrÅ¾e nedovoljno zastupljene populacije manje verovatno ukljuÄeni u skupovima podataka zbog primjenjenih metoda prikupljanja.

Å taviÅ¡e, veÄ‡i dio skupa podataka se Äisti odbacivanjem sadrÅ¾aja koji pominje ijednu rijeÄ sa liste od oko 400 "Prljavih, nestaÅ¡nih, opscenih ili na drugi naÄin loÅ¡ih rijeÄi" (en. _â€œDirty, Naughty, Obscene or Otherwise Bad Wordsâ€_). Kao da to veÄ‡ nije nedovoljan napor, rijeÄi na listi su preteÅ¾no rijeÄi vezane za seks, sa samo nekoliko rasnih uvreda i rijeÄi vezanih za "bijelu nadmoÄ‡".

Pored toga, uroÄ‘ena pristrasnost sadrÅ¾ana u tekstovima koje su napisali ljudi se direktno prenosi modelu. Studija _BERT_-a je pokazala da povezuje ljudske invaliditete sa viÅ¡e negativnih rijeÄi nego pozitivnih, kao i da su nasilje, beskuÄ‡niÅ¡tvo i zavisnost o drogama prekomjerno povezani sa mentalnim bolestima. Druga studija je pokazala da modeli sa ogromnim skupovima podataka kao Å¡to je _GPT-3_ generiÅ¡u reÄenice sa visokim nivoom toksiÄnosti Äak i kada im se daju netoksiÄni upiti. Ista studija je takoÄ‘e otkrila da je 272 hiljade dokumenata u podacima _GPT-2_-a doÅ¡lo od nepouzdanih vijesti i zabranjenih _subreddita_. Mirni druÅ¡tveni pokreti se zanemaruju u korist dramatiÄnih i nasilnih od strane medijskih izveÅ¡taja, pa tako ni oni ne ulaze u skup podataka.

Skupovi podataka su jednostavno preveliki da bi se temeljno obradili i dokumentovali, Å¡to znaÄi da je potrebna minimalna koliÄina odgovornosti nemoguÄ‡a.

## Posledice: ozbiljne.

NaÅ¡i modeli sada mogu koristiti, i Äesto koriste, pristrasne, uvredljive stavove i pogrdni jezik. A poÅ¡to ljudi imaju tendenciju da traÅ¾e (i izmiÅ¡ljaju) znaÄenje gdje ga nema, kao Å¡to i model generiÅ¡e vjeÅ¡taÄke tekstove koje ne razumije, sada imamo uvjerljivo inteligentnu maÅ¡inu koja Ä‡e rado pruÅ¾iti uÅ¾asne savjete ne razumijevajuÄ‡i Å¡ta zapravo govori.

Zato su ovi modeli nazvani "StohastiÄkim papagajima" (en. _Stochastic Parrots_) - jer oni samo ponavljaju fraze i informacije iz svoje baze podataka koje su na osnovu matematiÄke verovatnoÄ‡e povezane sa upitom koji im je dat. NasumiÄno ponavljaju stvari koje su "Äuli", bez ikakve ideje Å¡ta one zapravo znaÄe.

Ljudi su potom izloÅ¾eni novim stereotipima i iskrivljenim pogledima na svijet. Ili im se postojeÄ‡i pojaÄavaju. Drugi bivaju hapÅ¡eni zbog modela koji nepravilno prevodi njihov post "Dobro jutro!" kao teroristiÄku propagandu. Neki namerno koriste ovu specifiÄnu sposobnost koju modeli sada poseduju za kreiranje regrutacionih postova koji izgledaju kao da ih je napisao stvarni ljudski teoretiÄar zavjere.

A mi veÄ‡ ukljuÄujemo ove modele u razne vaÅ¾ne aspekte naÅ¡ih Å¾ivota kao Å¡to su medicina i obrazovanje.

## RjeÅ¡enja.

U navedenom radu, autori navode brojne naÄine kako moÅ¾emo poboljÅ¡ati i zaÅ¡tititi se od ovih problema pri stvaranju novih skupova podataka i obuÄavanju novih modela. ApelujuÄ‡i istraÅ¾ivaÄe da preÄ‘u na razmiÅ¡ljanje i paÅ¾ljivo planiranje prije nego Å¡to uopÅ¡te zapoÄnu poduhvat stvaranja AI-ja. RazmatrajuÄ‡i i planirajuÄ‡i finansijske i ekoloÅ¡ke troÅ¡kove razvoja unaprijed. SastavljajuÄ‡i skupove podataka koji direktno rjeÅ¡avaju zadatak, umjesto prikupljanja velike koliÄine opÅ¡tih podataka zbog pogodnosti.

Usvajanjem okvira koji definiÅ¡u za koje su namjene njihovi modeli pogodni, kao i pruÅ¾anjem detaljne dokumentacije o koriÅ¡tenim podacima, motivaciji za prikupljanje ovih podataka, kao i samom procesu prikupljanja podataka. Ne fokusirajuÄ‡i se na poveÄ‡anje modela kako bi se postigli bolji rezultati na raznim proizvoljnim rang listama. IstraÅ¾ujuÄ‡i moguÄ‡nost oznaÄavanja izlaza koji modeli kreiraju kako bi se omoguÄ‡ilo prepoznavanje teksta koji je napisala AI umjesto Äovjeka.

Krivica ne leÅ¾i na samim modelima, veÄ‡ na nama kao stvaraocima i naÄinu na koji to radimo. AI je najnoviji alat napravljen od strane ljudi i tu je da ostane. Ali moramo biti izuzetno paÅ¾ljivi i temeljni u naÅ¡im metodama prikupljanja i obrade podataka, i obuke modela, kako bismo osigurali da ovi alati budu korisni a ne Å¡tetni.

## ZakljuÄak.

Stigli ste do ovdje pa dozvolite da vam uÅ¡tedim trud skrolanja nazad do vrha: [nauÄni rad](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922). Autori izvrsno pokrivaju sve pomenute teme i mnogo viÅ¡e, referencirajuÄ‡i svoje izvore u svakom dijelu. Postoji mnogo toga Å¡to nisam pokrio u ovom Älanku, jer rad morate proÄitati sami. Do sljedeÄ‡eg puta!
